{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERA - DSCSP - Aula 28\n",
    "## Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introdução\n",
    "\n",
    "Na aula sobre clustering nós utilizamos diversos algoritmos de clustering e redução de dimensionalidade para conseguir encontrar relações de proximidade entre documentos. Entretanto, apesar de algoritmos como o PCA conseguirem representar reduzidamente o nosso conjunto de documentos, nós não conseguíamos interpretar o resultado obtido. Isso acontece porque o PCA encontra novos vetores de features que são combinações lineares do conjunto de palavras existentes. Esse fator pode não ser um problema se o que se deseja é apenas encontrar clusters sem interpretações mais profundas. Entretanto, muitas vezes gostaríamos de entender o racional por trás da geração dos clusters. Ainda mais, as vezes gostaríamos de reduzir um documento a um conjunto de palavras-chave que podem \"resumir\" o nosso documento e agrupá-las em **tópicos**. E é exatamente esse o objetivo dessa aula.\n",
    "\n",
    "A área de topic analysis é de grande importância para Machine Learning, ou mais especificamente a área de Data Mining. A utilização de tópicos nos permite ter uma melhor e mais compacta representação dos nossos dados, principalmente quando temos um conjunto extenso de dados e atributos (features). \n",
    "\n",
    "Utilizar topic analysis em Natural Language Processing (NLP) é algo bem intuitivo. Nós naturalmente fazemos isso quando queremos organizar textos (documentos) em diferentes categorias, ou temas. Por exemplo, nós podemos ler artigos do Google News e dizer facilmente que um determinado artigo tem o tema \"esporte\", ou o tema \"política\". Nosso trabalho em topic analysis é o de conseguir desenvolver algoritmos de Machine Learning que possam encontrar automaticamente esses tópicos, ou temas, por nós.\n",
    "\n",
    "Vamos definir a seguir alguns termos importantes que serão utilizados daqui por diante:\n",
    "- **documentos**: são conjuntos de atributos (normalmente palavras) associadas a amostras de uma população (ex: artigos do wikipedia, texto de um livro etc)\n",
    "- **atributos** (features): é o conjunto de variáveis observadas. Normalmente é um conjunto de palavras que compõe o vocabulário utilizado.\n",
    "- **variável latente**: variáveis, ou atributos, implícitas no sistema. No nosso caso, podem representar os tópicos dos documentos.\n",
    "- **vetor de atributos**: é a representação de um determinado documento a partir dos atributos pertencentes a ele\n",
    "- **matriz de frequência de termos**: é o empilhamento de diversos vetores de atributos associados a cada documento. Cada documento representa uma linha na matriz, enquanto as colunas representam os atributos dos documentos.\n",
    "\n",
    "<img src=\"../imagens/mat_freq.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a praticar!\n",
    "\n",
    "Primeiro vamos realizar os imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports usados no curso\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Lembre-se de colocar os datasets baixados dentro de uma pasta \"datasets\" na raiz da pasta clonada do repositório da aula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pasta contendo os dados:\n",
    "DATASET_FOLDER = '../datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós vamos começar utilizando o conhecido dataset de artigos do Wikipedia. Para começar leve, vamos replicar uma parte do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>artigo</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Sabbath</td>\n",
       "      <td>Black Sabbath are an English rock band, formed...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Lymphoma is a type of blood cancer that occurs...</td>\n",
       "      <td>Sickness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hepatitis C</td>\n",
       "      <td>Hepatitis C is an infectious disease affecting...</td>\n",
       "      <td>Sickness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HTTP cookie</td>\n",
       "      <td>A cookie, also known as an HTTP cookie, web co...</td>\n",
       "      <td>Internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global warming</td>\n",
       "      <td>Global warming is the rise in the average temp...</td>\n",
       "      <td>Global_Warming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           titulo                                             artigo  \\\n",
       "0   Black Sabbath  Black Sabbath are an English rock band, formed...   \n",
       "1        Lymphoma  Lymphoma is a type of blood cancer that occurs...   \n",
       "2     Hepatitis C  Hepatitis C is an infectious disease affecting...   \n",
       "3     HTTP cookie  A cookie, also known as an HTTP cookie, web co...   \n",
       "4  Global warming  Global warming is the rise in the average temp...   \n",
       "\n",
       "          cluster  \n",
       "0           Music  \n",
       "1        Sickness  \n",
       "2        Sickness  \n",
       "3        Internet  \n",
       "4  Global_Warming  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abra o dataset\n",
    "df_wiki = pd.read_csv(os.path.join(DATASET_FOLDER, 'wikipedia_dataset_60.csv'), sep=',', names=['titulo', 'artigo', 'cluster'])\n",
    "\n",
    "df_wiki.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre que os clusters indicados foram feitos apenas para fins didáticos. Na maioria das vezes nós não teremos informações a respeito da relação entre documentos. Realizar esse processo seria trabalhoso demais para a maioria das situações envolvendo Machine Learning. E é exatamente esse tipo de trabalho que queremos automatizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número aproximado de clusters\n",
    "n_clusters = len(pd.unique(df_wiki['cluster']))\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Sabbath: \n",
      "Black Sabbath are an English rock band, formed in Birmingham in 1968, by guitarist Tony Iommi, bassist Geezer Butler, singer Ozzy Osbourne, and drummer Bill Ward. The band has since experienced multiple line-up changes, with Tony Iommi the only constant presence in the band through the years. Originally formed in 1968 as a heavy blues rock band named Earth, the band began incorporating occult themes with horror-inspired lyrics and tuned-down guitars. Despite an association with occult and horror themes, Black Sabbath also composed songs dealing with social instability, political corruption, the dangers of drug abuse and apocalyptic prophecies of the horrors of war. Osbourne's heavy drug use led to his dismissal from the band in 1979. He was replaced by former Rainbow vocalist Ronnie James Dio. After a few albums with Dio's vocals and songwriting collaborations, Black Sabbath endured a revolving line-up in the 1980s and '90s that included vocalists Ian Gillan, Glenn Hughes, Ray Gillen a (...)\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de um artigo:\n",
    "# Vamos mostrar apenas 1000 caracteres\n",
    "print(\"Black Sabbath: \\n{} (...)\".format(df_wiki[df_wiki.titulo=='Black Sabbath']['artigo'].values[0][:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar agora um embedding para esse texto. Nós utilizaremos uma abordagem de Bag-of-Words (BOW) para esse problema. Mais especificamente, vamos utilizar o Tf-Idf com um tamanho de vocabulário de 15000 palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 15000)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importe o método TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Crie o vetor de embeddings Tf-Idf\n",
    "# Vamos definir o número máximo de palavras do nosso dicionário (número de dimensões)\n",
    "# igual a 15000. \n",
    "# Também utilizamos um corte em termos muito frequentes em um dado\n",
    "# documento: max_df=0.8\n",
    "# Igualmente, realizamos um corte de termos muito pouco frequentes: min_df=0.01\n",
    "# O parâmetro sublinear_tf utiliza a função 1+log(tf) em vez de uma função linear\n",
    "# para calcular o peso da frequência de cada termo. Isso permite uma função mais \"suave\"\n",
    "# use_idf: Utiliza o inverso da frequência do documento para recriar os pesos da matriz\n",
    "tfidf = TfidfVectorizer(max_df=0.8, min_df=0.01, max_features=15000, sublinear_tf=True, use_idf=True)\n",
    "\n",
    "# Precisamos extrair os artigos e títulos do dataframe\n",
    "titles = df_wiki['titulo'].values\n",
    "articles = df_wiki['artigo'].values\n",
    "\n",
    "# Aplique a transformação nos artigos\n",
    "X = tfidf.fit_transform(articles)\n",
    "\n",
    "# Tamanho do dataset\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja algumas palavras que fazem parte do nosso vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coldfield',\n",
       " 'vml',\n",
       " 'música',\n",
       " 'directional',\n",
       " 'feeling',\n",
       " 'india',\n",
       " 'tussauds',\n",
       " 'examination',\n",
       " 'tolson',\n",
       " 'insurer',\n",
       " 'animated',\n",
       " 'fourier',\n",
       " 'fertile',\n",
       " 'presents',\n",
       " 'baseball',\n",
       " 'anywhere',\n",
       " 'agrees',\n",
       " 'rescuing',\n",
       " 'seven',\n",
       " 'freddie']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tfidf.vocabulary_.keys())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que temos 58 documentos (número de linhas) por 15000 atributos (palavras - colunas). Essa matriz é o que definimos anteriormente por **matriz de frequência de palavras**.\n",
    "\n",
    "Como temos uma dimensão muito elevada, nós podemos realizar algumas alternativas para reduzir a dimensionalidade. A primeira alternativa é o PCA, mas, como já dissemos anteriormente, ele não nos permite ter uma interpretação dos resultados. Portanto, precisamos de outras alternativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization (NMF)\n",
    "\n",
    "O [NMF](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization) é um algoritmo poderoso (apesar de relativamente simples) para encontrar tópicos em um conjunto de documentos e features. Ele se baseia em um processo de decomposição de matrizes para criar uma representação adequada da matriz de frequência de palavras (denotado por **A**). Mais especificamente, o NMF decompõe a matriz de frequência de palavras em duas: a primeira é a matriz de pesos (chamada de **W**), com as linhas representando os documentos e as colunas indicando os tópicos; e a segunda é a matriz de atributos (chamada de **H**), com as linhas indicando os tópicos e as colunas os atributos. O número de tópicos é definido antecipadamente e é fixo.\n",
    "\n",
    "<img src=\"../imagens/nmf_draw.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "As duas matrizes são formadas a partir de um processo iterativo de otimização (veja esse [link](http://www.columbia.edu/~jwp2128/Teaching/E4903/papers/nmf_nature.pdf) para mais detalhes) com o objetivo de reconstruir fielmente a matriz **A**. Entretanto, para esse fim, a matriz **A** não pode possuir entradas negativas.\n",
    "\n",
    "Vamos aplicar esse método no problema dos artigos do Wikipedia!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro, importe o módulo NMF do scikit-learn\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Precisamos criar a instância do NMF\n",
    "# Temos que definir um número de componentes para o NMF\n",
    "# Como temos 6 clusters, vamos escolher n_components=6\n",
    "nmf = NMF(n_components=6)\n",
    "\n",
    "# Agora vamos utilizar os mesmos atributos fit, transform ou fit_transform\n",
    "# que já conhecemos do universo do sklearn\n",
    "W_nmf = nmf.fit_transform(X)\n",
    "\n",
    "# Vamos ver qual é a dimensão de W_nmf\n",
    "W_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o número de linhas se manteve em 58, que é o número de documentos (artigos) que nós temos, e o número de colunas se transformou em 6, que é o número de tópicos que nós escolhemos. Essa matriz gerada representa a matriz **W** (matriz de pesos) da fatoração de matrizes.\n",
    "\n",
    "Vamos agora achar a matriz **H** que representa a matriz de atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o número de linhas é igual ao número de tópicos e o número de colunas representa o número de palavras no nosso vocabulário. Cada linha da matriz é definida como um componente (assim como o PCA possui os componentes principais) que está associado a um tópico específico. Entretanto, diferentemente do PCA, nós podemos associar cada componente a um conjunto específico de palavras. Vamos verificar abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topico 0:\n",
      "----------\n",
      "film       0.229489\n",
      "she        0.216039\n",
      "starred    0.190290\n",
      "her        0.186475\n",
      "award      0.161707\n",
      "Name: 0, dtype: float64\n",
      "----------\n",
      "Topico 1:\n",
      "----------\n",
      "treatment    0.162089\n",
      "disease      0.138412\n",
      "symptoms     0.133852\n",
      "infection    0.130183\n",
      "blood        0.120872\n",
      "Name: 1, dtype: float64\n",
      "----------\n",
      "Topico 2:\n",
      "----------\n",
      "cup       0.131772\n",
      "scored    0.126316\n",
      "fifa      0.116954\n",
      "goals     0.113098\n",
      "team      0.108376\n",
      "Name: 2, dtype: float64\n",
      "----------\n",
      "Topico 3:\n",
      "----------\n",
      "climate       0.229481\n",
      "emissions     0.189357\n",
      "conference    0.131514\n",
      "greenhouse    0.125997\n",
      "change        0.121090\n",
      "Name: 3, dtype: float64\n",
      "----------\n",
      "Topico 4:\n",
      "----------\n",
      "users     0.160605\n",
      "web       0.158407\n",
      "search    0.152476\n",
      "google    0.147216\n",
      "user      0.141580\n",
      "Name: 4, dtype: float64\n",
      "----------\n",
      "Topico 5:\n",
      "----------\n",
      "album    0.163353\n",
      "band     0.144849\n",
      "song     0.111544\n",
      "tour     0.104336\n",
      "songs    0.090645\n",
      "Name: 5, dtype: float64\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Precisamos criar uma lista de palavras que representam as \n",
    "# colunas da matriz de frequência de palavras\n",
    "words = [x[0] for x in sorted(tfidf.vocabulary_.items())]\n",
    "\n",
    "# Vamos criar um dataframe para visualizar\n",
    "components_df = pd.DataFrame(nmf.components_, columns=words)\n",
    "\n",
    "# Vamos verificar as palavras que representam cada um dos tópicos\n",
    "for i in range(6):\n",
    "    component = components_df.iloc[i]\n",
    "    print(\"Topico {}:\".format(i))\n",
    "    print(\"----------\")\n",
    "    print(component.nlargest())\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que achou da distribuição de palavras dentro de cada tópico? Acha que faz sentido com os temas principais dos artigos do Wikipedia? Cada um dos tópicos poderia ser associado a um cluster?\n",
    "\n",
    "Podemos ainda verificar quais são os tópicos principais de alguns artigos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.313460\n",
      "1    0.000000\n",
      "2    0.017112\n",
      "3    0.003640\n",
      "4    0.000000\n",
      "5    0.002074\n",
      "Name: Denzel Washington, dtype: float64\n",
      "\n",
      "0    0.005121\n",
      "1    0.495843\n",
      "2    0.000447\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "Name: Leukemia, dtype: float64\n",
      "\n",
      "0    0.016562\n",
      "1    0.000000\n",
      "2    0.513333\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "5    0.034787\n",
      "Name: Neymar, dtype: float64\n",
      "\n",
      "0    0.024219\n",
      "1    0.000000\n",
      "2    0.035836\n",
      "3    0.043306\n",
      "4    0.377178\n",
      "5    0.010995\n",
      "Name: LinkedIn, dtype: float64\n",
      "\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.009951\n",
      "3    0.000000\n",
      "4    0.019734\n",
      "5    0.588312\n",
      "Name: Arctic Monkeys, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Precisamos criar um dataframe para facilitar nossa vida\n",
    "df = pd.DataFrame(W_nmf, index=titles)\n",
    "\n",
    "print(df.loc['Denzel Washington'])\n",
    "print()\n",
    "print(df.loc['Leukemia'])\n",
    "print()\n",
    "print(df.loc['Neymar'])\n",
    "print()\n",
    "print(df.loc['LinkedIn'])\n",
    "print()\n",
    "print(df.loc['Arctic Monkeys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que os artigos possuem tópicos coerentes com o que esperávamos!\n",
    "\n",
    "Vamos agrupar agora os artigos pelos tópicos principais de cada um deles e ver como eles tém relação com os clusters definidos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          article  label\n",
      "10                                   Jessica Biel      0\n",
      "19                                 Angelina Jolie      0\n",
      "18                                     Mila Kunis      0\n",
      "38                                  Anne Hathaway      0\n",
      "5                            Catherine Zeta-Jones      0\n",
      "46                             Michael Fassbender      0\n",
      "7                               Denzel Washington      0\n",
      "50                               Jennifer Aniston      0\n",
      "25                                 Dakota Fanning      0\n",
      "12                                  Russell Crowe      0\n",
      "49                                    Tonsillitis      1\n",
      "31                                       Leukemia      1\n",
      "24                                          Fever      1\n",
      "52                                     Prednisone      1\n",
      "9                                            Gout      1\n",
      "8                                     Hepatitis B      1\n",
      "34                                    Doxycycline      1\n",
      "2                                     Hepatitis C      1\n",
      "1                                        Lymphoma      1\n",
      "21                                     Gabapentin      1\n",
      "48                                   Arsenal F.C.      2\n",
      "26                Colombia national football team      2\n",
      "28                  France national football team      2\n",
      "17                                         Neymar      2\n",
      "53                                  Franck Ribéry      2\n",
      "54              2014 FIFA World Cup qualification      2\n",
      "11                             Zlatan Ibrahimović      2\n",
      "6                                        Football      2\n",
      "44                              Cristiano Ronaldo      2\n",
      "36                                 Radamel Falcao      2\n",
      "37  Greenhouse gas emissions by the United States      3\n",
      "35                                   Nigel Lawson      3\n",
      "33                                        350.org      3\n",
      "41                                 Kyoto Protocol      3\n",
      "30                               Connie Hedegaard      3\n",
      "47       Nationally Appropriate Mitigation Action      3\n",
      "43  2007 United Nations Climate Change Conference      3\n",
      "15                                 Climate change      3\n",
      "4                                  Global warming      3\n",
      "45  2010 United Nations Climate Change Conference      3\n",
      "55                                 Alexa Internet      4\n",
      "51                                       LinkedIn      4\n",
      "57                                         Tumblr      4\n",
      "40                              Internet Explorer      4\n",
      "39                                       HTTP 404      4\n",
      "56                                  Google Search      4\n",
      "23                                  Social search      4\n",
      "22                                        Firefox      4\n",
      "3                                     HTTP cookie      4\n",
      "32                                         Sepsis      5\n",
      "29                          Red Hot Chili Peppers      5\n",
      "27                                     Nate Ruess      5\n",
      "20                                   Stevie Nicks      5\n",
      "16                                     The Wanted      5\n",
      "14                                 Arctic Monkeys      5\n",
      "13                                       Skrillex      5\n",
      "42                                   Chad Kroeger      5\n",
      "0                                   Black Sabbath      5\n"
     ]
    }
   ],
   "source": [
    "# Cria as labels a partir do tópico mais relevante de cada artigo\n",
    "labels = np.argmax(W_nmf, axis=1)\n",
    "\n",
    "# Cria o novo dataframe com os labels dos clusters\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# Apresenta os resultados\n",
    "print(df.sort_values(by='label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que achou do resultado? Percebeu que o NMF não só encontrou uma representação em tópicos dos documentos, mas também teve um papel de agregador? Ele realizou um ótimo trabalho em encontrar clusters. E o melhor, nós podemos explicar com palavras o que representa cada um dos tópicos/clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Vamos praticar um pouco com o NMF. O dataset que vamos utilizar é um dataset padrão do scikit-learn que é muito útil para algoritmos de NLP. O dataset contém grupos de discussão no [Usenet](https://en.wikipedia.org/wiki/Usenet) com 18.000 postagens e 20 tópicos principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importe o dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Vamos escolher apenas algumas categorias para facilitar\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Pegamos apenas o corpo do texto\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, categories=categories,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Para limitar um pouco a quantidade de dados, vamos limitar o dataset\n",
    "X = dataset.data[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rick Anderson replied to my letter with...\n",
      "\n",
      "ra> In article <C5ELp2.L0C@acsu.buffalo.edu>,\n",
      "ra>\n",
      "ra> >     Well, Jason, it's heretical in a few ways. The first point is that\n",
      "ra> >     this equates Lucifer and Jesus as being the same type of being.\n",
      "ra> >     However, Lucifer is a created being: \"Thou [wast] perfect in thy\n",
      "ra> >     ways from the day that thou wast created, till iniquity was found in\n",
      "ra> >     thee.\" (Ezekiel 28:15). While Jesus is uncreated, and the Creator of\n",
      "ra> >     all things: \"In the beginning was the Word, and the Word was with\n",
      "ra> >     God, and the Word was God.  The same was in the beginning with God.\n",
      "ra> >     All things were made by him; and without him was not any thing made\n",
      "ra> >     that was made.\" (John 1:1-3) \"And he is before all things, and by\n",
      "ra> >     him all things consist.\" (Colossians 1:17)\n",
      "ra>\n",
      "ra>    Your inference from the Ezekiel and John passages that Lucifer was\n",
      "ra> \"created\" and that Jesus was not depends on a particular interpetation of\n",
      "ra> the word \"create\" -- one with which many Christians may not agree.\n",
      "ra> Granted the Mormon belief that all of God's children (including Christ\n",
      "ra> and Lucifer) are eternally existent intelligences which were \"organized\"\n",
      "ra> into spirit children by God, the term \"creation\" can apply equally well\n",
      "ra> to both of those passages.\n",
      "\n",
      "     Just briefly, on something that you mentioned in passing. You refer to\n",
      "     differing interpretations of \"create,\" and say that many Christians may\n",
      "     not agree. So what? That is really irrelevant. We do not base our faith\n",
      "     on how many people think one way or another, do we? The bottom line is\n",
      "     truth, regardless of popularity of opinions.\n",
      "\n",
      "     Also, I find it rather strange that in trying to persuade that created\n",
      "     and eternally existent are equivalent, you say \"granted the Mormon\n",
      "     belief...\" You can't grant your conclusion and then expect the point to\n",
      "     have been addressed. In order to reply to the issue, you have to address\n",
      "     and answer the point that was raised, and not just jump to the\n",
      "     conclusion that you grant.\n",
      "\n",
      "     The Bible states that Lucifer was created.  The Bible states that Jesus\n",
      "     is the creator of all. The contradiction that we have is that the LDS\n",
      "     belief is that Jesus and Lucifer were the same.\n",
      "\n",
      "ra> >     Your point that we all are brothers of Jesus and Lucifer is also\n",
      "ra> >     heretical, since we are not innately brothers and sisters of Christ.\n",
      "ra> >     We are adopted, \"For ye have not received the spirit of bondage\n",
      "ra> >     again to fear; but ye have received the Spirit of adoption, whereby\n",
      "ra> >     we cry, Abba, Father.\" (Romans 8:15); and not the natural children\n",
      "ra> >     of God. It is only through faith that we even enter the family of\n",
      "ra> >     God; \"For ye are all the children of God by faith in Christ Jesus.\"\n",
      "ra> >     (Galatians 3:26). And it is only through the manifestation of this\n",
      "ra> >     faith in receiving Jesus that we are become the sons of God.  \"But\n",
      "ra> >     as many as received him, to them gave he power to become the sons of\n",
      "ra> >     God, [even] to them that believe on his name: Which were born, not\n",
      "ra> >     of blood, nor of the will of the flesh, nor of the will of man, but\n",
      "ra> >     of God.\" (John 1:12-13)\n",
      "ra>\n",
      "ra>    Has it occured to you, Robert, that being \"born of\" someone or being\n",
      "ra> of that person (or Person)'s \"family\" may be a symbolic term in the New\n",
      "ra> Testament?  Mormons believe that we are \"adopted\" into the House of\n",
      "ra> Israel through baptism and faith in Christ, although some have expressed\n",
      "ra> belief that this does evince a physical change in our bodies.\n",
      "\n",
      "     The Mormon belief is that all are children of God. Literally. There is\n",
      "     nothing symbolic about it. This however, contradicts what the Bible\n",
      "     says. The Bible teaches that not everyone is a child of God:\n",
      "\n",
      "          The field is the world; the good seed are the children of the \n",
      "          kingdom; but the tares are the children of the wicked [one];\n",
      "          (Matthew 13:38)\n",
      "\n",
      "          I speak that which I have seen with my Father: and ye do that which \n",
      "          ye have seen with your father. (John 8:38)\n",
      "\n",
      "          Ye do the deeds of your father. Then said they to him, We be not \n",
      "          born of fornication; we have one Father, [even] God.  Jesus said \n",
      "          unto them, If God were your Father, ye would love me: for I \n",
      "          proceeded forth and came from God; neither came I of myself, but he \n",
      "          sent me.  Why do ye not understand my speech? [even] because ye \n",
      "          cannot hear my word.  Ye are of [your] father the devil, and the \n",
      "          lusts of your father ye will do. He was a murderer from the \n",
      "          beginning, and abode not in the truth, because there is no truth in \n",
      "          him. When he speaketh a lie, he speaketh of his own: for he is a \n",
      "          liar, and the father of it. (John 8:41-44)\n",
      "\n",
      "          And said, O full of all subtilty and all mischief, [thou] child of \n",
      "          the devil, [thou] enemy of all righteousness, wilt thou not cease \n",
      "          to pervert the right ways of the Lord? (Acts 13:10)\n",
      "\n",
      "          Wherein in time past ye walked according to the course of this \n",
      "          world, according to the prince of the power of the air, the spirit \n",
      "          that now worketh in the children of disobedience: (Ephesians 2:2)\n",
      "\n",
      "          In this the children of God are manifest, and the children of the \n",
      "          devil: whosoever doeth not righteousness is not of God, neither he \n",
      "          that loveth not his brother. (1 John 3:10)\n",
      "\n",
      "     One becomes a child of God...\n",
      "\n",
      "          But as many as received him, to them gave he power to become the\n",
      "          sons of God, [even] to them that believe on his name: (John 1:12)\n",
      "\n",
      "          Behold, what manner of love the Father hath bestowed upon us, that\n",
      "          we should be called the sons of God: therefore the world knoweth us\n",
      "          not, because it knew him not.  Beloved, now are we the sons of God,\n",
      "          and it doth not yet appear what we shall be: but we know that, when\n",
      "          he shall appear, we shall be like him; for we shall see him as he\n",
      "          is. (1 John 3:1-2)\n",
      "\n",
      "     ...when he is born again through faith in Jesus Christ:\n",
      "\n",
      "          Which were born, not of blood, nor of the will of the flesh, nor of\n",
      "          the will of man, but of God. (John 1:13)\n",
      "\n",
      "          Having predestinated us unto the adoption of children by Jesus\n",
      "          Christ to himself, according to the good pleasure of his will,\n",
      "          (Ephesians 1:5)\n",
      "\n",
      "          Of his own will begat he us with the word of truth, that we should\n",
      "          be a kind of firstfruits of his creatures. (James 1:18)\n",
      "\n",
      "          For as many as are led by the Spirit of God, they are the sons of\n",
      "          God. For ye have not received the spirit of bondage again to fear;\n",
      "          but ye have received the Spirit of adoption, whereby we cry, Abba,\n",
      "          Father. The Spirit itself beareth witness with our spirit, that we\n",
      "          are the children of God: (Romans 8:14-16)\n",
      "\n",
      "          Beloved, let us love one another: for love is of God; and every one\n",
      "          that loveth is born of God, and knoweth God. (1 John 4:7)\n",
      "\n",
      "          Whosoever believeth that Jesus is the Christ is born of God: and\n",
      "          every one that loveth him that begat loveth him also that is\n",
      "          begotten of him. (1 John 5:1)\n",
      "\n",
      "          For ye are all the children of God by faith in Christ Jesus.\n",
      "          (Galatians 3:26)\n",
      "\n",
      "ra> >     We are told that, \"And this is life eternal, that they might know\n",
      "ra> >     thee the only true God, and Jesus Christ, whom thou hast sent.\"\n",
      "ra> >     (John 17:3). Life eternal is to know the only true God. Yet the\n",
      "ra> >     doctrines of the LDS that I have mentioned portray a vastly\n",
      "ra> >     different Jesus, a Jesus that cannot be reconciled with the Jesus of\n",
      "ra> >     the Bible. They are so far removed from each other that to proclaim\n",
      "ra> >     one as being true denies the other from being true. According to the\n",
      "ra> >     Bible, eternal life is dependent on knowing the only true God, and\n",
      "ra> >     not the construct of imagination.\n",
      "ra>\n",
      "ra>\n",
      "ra>    Robert, with all due respect, who died and left you Chief Arbiter of\n",
      "ra> Correct Biblical Interpretation?  I don't mean to be snotty about this,\n",
      "ra> but the fact is that the Bible is so differently interpreted by different\n",
      "ra> groups of Biblical scholars (what do you think of the Jehovah's\n",
      "ra> Witnesses, for example?) that to make reference to the \"Jesus of the\n",
      "ra> Bible\" is simply ridiculous.  Whose \"Jesus of the Bible\" do you mean?\n",
      "\n",
      "     This is really a red herring. It doesn't address any issue raised, but \n",
      "     rather, it seeks to obfuscate. The fact that some groups try to read \n",
      "     something into the Bible, doesn't change what the Bible teaches. For \n",
      "     example, the fact that the Jehovah's Witnesses deny the Deity of Christ \n",
      "     does not alter what the Bible teaches [ \"Looking for that blessed hope,\n",
      "     and the glorious appearing of the great God and our Saviour Jesus\n",
      "     Christ;\" (Titus 2:13),\"Simon Peter, a servant and an apostle of Jesus\n",
      "     Christ, to them that have obtained like precious faith with us through\n",
      "     the righteousness of God and our Saviour Jesus Christ:\" (2 Peter 1:1)] \n",
      "     on the Deity of Christ.\n",
      "\n",
      "     We first look to the Bible to see what it teaches. To discount, or not \n",
      "     even address, what the Bible teaches because there are some groups that \n",
      "     have differing views is self-defeating. To see what the Bible teaches, \n",
      "     you have to look at the Bible.\n",
      "\n",
      "ra> >     \"Our Lord's mortality was essential to his own salvation\" (_The\n",
      "ra> >     Promised Messiah_, p. 456), \"He had to work out his own salvation by\n",
      "ra> >     doing the will of the Father in all things\" (ibid., p.54), \"he had\n",
      "ra> >     to be baptized to gain admission to the celestial kingdom\" (_Mormon\n",
      "ra> >     Doctrine_, p.71).\n",
      "ra>\n",
      "ra>    Welcome to the wonderful world of Mormon paradoctrine, Robert.  The\n",
      "ra> above books are by the late Bruce R. McConkie, a former general authority\n",
      "ra> of the LDS Church.  Those books were not published by the Church, nor do\n",
      "ra> they constitute \"offical doctrine.\"  They consist of his opinions.  Now,\n",
      "ra> does that mean that what he says is not true?  Not at all; I'll have to\n",
      "ra> think about the idea of Christ's personal salvation before I come to any\n",
      "ra> conclusions myself.  The conclusions I come to may seem \"heretical\" to\n",
      "ra> you, but I'm prepared to accept that.\n",
      "\n",
      "     I find this rather curious. When I mentioned that the Mormon belief is\n",
      "     that Jesus needed to be saved, I put forward some quotes from the late\n",
      "     apostle, Bruce McConkie. The curious part is that no one addressed the\n",
      "     issue of `Jesus needing to be saved.' Rick comes the closest with his \"I\n",
      "     have my own conclusions\" to addressing the point.\n",
      "\n",
      "     Most of the other replies have instead hop-scotched to the issue of\n",
      "     Bruce McConkie and whether his views were 'official doctrine.' I don't\n",
      "     think that it matters if McConkie's views were canon. That is not the\n",
      "     issue.  Were McConkie's writings indicative of Mormon belief on this\n",
      "     subject is the real issue. The indication from Rick is that they may \n",
      "     certainly be.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemplos de documentos\n",
    "print(\"\\n\".join(data_samples[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos que os dados estão um pouco sujos e tem diversas palavras que podem não significar muito para nós.\n",
    "\n",
    "Crie o vetor de Bag-of-Words Tf-Idf a partir dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Crie a matriz de frequência de palavras utilizando Tf-Idf\n",
    "# Dica: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
