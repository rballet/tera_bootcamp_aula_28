{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERA - DSCSP - Aula 28\n",
    "## Topic Analysis - Case (Solução)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case\n",
    "\n",
    "Esse case foi retirado desse [artigo](https://towardsdatascience.com/topic-modeling-for-the-new-york-times-news-dataset-1f643e15caac). O objetivo dele é verificar se conseguimos extrair tópicos relevantes de um dataset contendo 8.447 matérias do NY Times, com um vocabulário de 3.012 palavras. Por razão de direitos autorias, os documentos não possuem título.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1400/1*toWf7lAVf_5GIb9IMfS8Bw.jpeg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo `nyt_data.txt` contém os documentos, onde cada linha representa um documento específico. O dataset já sofreu um processo de limpeza e vetorização, onde foram mantidas apenas palavras que ocorreram mais de 10 vezes. Cada palavra é representada por um índice, que pode ser acessado pelo arquivo `nyt_vocab.txt`, e por sua frequência no documento.\n",
    "\n",
    "Vamos criar a matriz de frequências a partir desses dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Contém os documentos do dataset:\n",
    "# Cada linha representa um documento\n",
    "# Cada documento contém um conjunto de índices de palavras e \n",
    "# a sua frequência no documento -> word_idx:term_freq\n",
    "with open(os.path.join(DATASET_FOLDER, 'nyt_data.txt')) as f:\n",
    "    documents = f.readlines()\n",
    "documents = [x.strip().strip('\\n').strip(\"'\") for x in documents] \n",
    "\n",
    "# Contém o vocabulário do dataset:\n",
    "# Cada linha representa o índice da palavra\n",
    "with open(os.path.join(DATASET_FOLDER, 'nyt_vocab.txt')) as f:\n",
    "    vocabs = f.readlines()\n",
    "vocabs = [x.strip().strip('\\n').strip(\"'\") for x in vocabs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar um exemplo de documento e vocabulários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 0:\n",
      " 1946:2,1168:2,1194:2,1275:1,777:1,522:1,107:1,839:2,424:2,2330:2,1878:2,344:1,1008:1,94:3,735:1,212:1,2407:1,2623:1,781:2,42:1,160:1,1141:1,117:1,16:1,108:1,153:2,1137:2,416:1,23:2,46:1,734:2,284:1,207:2,301:1,357:1,780:2,2564:2,206:1,106:2,892:1,272:1,1557:1,2003:1,1079:2,370:1,1894:2,266:1,143:1,1532:1,2551:1,223:2,30:1,1509:1,1921:2,361:2,311:1,1549:2,203:1,2821:1,546:2,1612:1,200:1,247:2,1731:2,565:1,2253:1,234:1,72:1,648:1,1072:1,518:1,39:1,703:2,625:1,140:1,2301:1,32:1,462:1,743:1,2017:2,925:1,118:1,1000:2,836:1,161:1,942:2,885:1,267:1,2683:1,626:1,317:1,69:1,860:2,633:1,2658:1,75:2,1563:1,690:1,802:1,1650:1,1836:1,111:1,2151:1,128:2,2864:1,22:2,1301:1,250:2,1922:2,936:1,918:1,775:1,280:1,18:2,182:1,667:1,2383:1,878:1,1498:1,109:2,1577:1,1758:1,60:1,2269:1,215:1,2038:2,485:1,335:1,2543:2,422:1,12:1,585:2,1754:1,1293:1,604:1,52:1,248:1,2:2,603:2,1345:2,271:3,668:1,1022:2,260:1,1251:2,498:1,2213:1,351:3,2584:1,1349:1,334:2,218:1,34:1,256:1,2576:2,58:1,1637:1,926:2,313:1,2041:2,1505:1,1698:2,587:1\n",
      "\n",
      "Parte do vocabulário:\n",
      " ['company', 'percent', 'state', 'play', 'official', 'game', 'man', 'city', 'plan', 'school']\n"
     ]
    }
   ],
   "source": [
    "print(\"Documento 0:\\n\", documents[0])\n",
    "print(\"\\nParte do vocabulário:\\n\", vocabs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora criar a matriz de frequência de termos **A** a partir dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8447, 3012)\n"
     ]
    }
   ],
   "source": [
    "# Número de documentos\n",
    "n_doc = 8447\n",
    "# Número de palavras\n",
    "n_words = 3012 \n",
    "A = np.zeros([n_doc,n_words])\n",
    "\n",
    "for j in range(len(documents)):\n",
    "    for i in documents[j].split(','):\n",
    "        word, freq = i.split(':')\n",
    "        A[j,int(word)-1] = int(freq)\n",
    "        \n",
    "# Tamanho da matriz de frequência de termos:\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora estamos prontos para realizar o processo de topic analysis! Divirta-se!\n",
    "\n",
    "*Dica: Utilize entre 20 e 25 tópicos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8447, 25)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro, importe o módulo NMF do scikit-learn\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Precisamos criar a instância do NMF\n",
    "# Vamos escolher 25 tópicos\n",
    "n_topics = 25\n",
    "nmf = NMF(n_components=n_topics)\n",
    "\n",
    "# Agora vamos utilizar os mesmos atributos fit, transform ou fit_transform\n",
    "# que já conhecemos do universo do sklearn\n",
    "W_nmf = nmf.fit_transform(A)\n",
    "\n",
    "# Vamos ver qual é a dimensão de W_nmf\n",
    "W_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o número de linhas se manteve em 8447, que é o número de documentos (artigos) que nós temos, e o número de colunas se transformou em 25, que é o número de tópicos que nós escolhemos. Essa matriz gerada representa a matriz **W** (matriz de pesos) da fatoração de matrizes.\n",
    "\n",
    "Vamos agora achar a matriz **H** que representa a matriz de atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3012)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_nmf = nmf.components_\n",
    "H_nmf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o número de linhas é igual ao número de tópicos e o número de colunas representa o número de palavras no nosso vocabulário. Cada linha da matriz é definida como um componente (assim como o PCA possui os componentes principais) que está associado a um tópico específico. Entretanto, diferentemente do PCA, nós podemos associar cada componente a um conjunto específico de palavras. Vamos verificar abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topico 0:\n",
      "----------\n",
      "question     3.871823\n",
      "thing        3.100133\n",
      "point        2.938836\n",
      "problem      2.428964\n",
      "issue        2.416854\n",
      "change       2.412662\n",
      "believe      2.399133\n",
      "mean         2.317026\n",
      "public       2.179699\n",
      "different    2.172736\n",
      "Name: 0, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 1:\n",
      "----------\n",
      "thing     3.250954\n",
      "tell      2.853146\n",
      "ask       2.684436\n",
      "feel      2.199998\n",
      "lot       1.947914\n",
      "little    1.926030\n",
      "start     1.801750\n",
      "room      1.640593\n",
      "keep      1.610485\n",
      "really    1.577409\n",
      "Name: 1, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 2:\n",
      "----------\n",
      "company     6.297112\n",
      "business    2.608162\n",
      "sell        2.521198\n",
      "share       2.332406\n",
      "stock       2.245064\n",
      "buy         2.008349\n",
      "market      1.848729\n",
      "sale        1.670624\n",
      "large       1.559963\n",
      "industry    1.463872\n",
      "Name: 2, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 3:\n",
      "----------\n",
      "game       4.641119\n",
      "play       3.908135\n",
      "team       3.753881\n",
      "season     3.225454\n",
      "win        3.129571\n",
      "second     2.980308\n",
      "player     2.878549\n",
      "victory    2.227106\n",
      "score      2.101710\n",
      "point      2.021600\n",
      "Name: 3, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 4:\n",
      "----------\n",
      "city         3.446013\n",
      "building     3.363895\n",
      "area         2.809594\n",
      "build        2.761112\n",
      "house        2.149373\n",
      "resident     1.986338\n",
      "project      1.809323\n",
      "home         1.805538\n",
      "community    1.715614\n",
      "site         1.653564\n",
      "Name: 4, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 5:\n",
      "----------\n",
      "police       5.467905\n",
      "officer      2.821238\n",
      "arrest       2.022413\n",
      "charge       1.789802\n",
      "city         1.693060\n",
      "kill         1.634217\n",
      "car          1.585178\n",
      "yesterday    1.492565\n",
      "man          1.445619\n",
      "crime        1.418485\n",
      "Name: 5, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 6:\n",
      "----------\n",
      "pay        3.136426\n",
      "money      2.688984\n",
      "state      2.355149\n",
      "budget     2.290895\n",
      "tax        2.251055\n",
      "cut        2.218244\n",
      "program    2.153985\n",
      "cost       1.957951\n",
      "plan       1.887041\n",
      "bill       1.640464\n",
      "Name: 6, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 7:\n",
      "----------\n",
      "serve     2.043529\n",
      "minute    1.885438\n",
      "add       1.850722\n",
      "pepper    1.668857\n",
      "food      1.660280\n",
      "oil       1.630964\n",
      "cook      1.583000\n",
      "cup       1.570240\n",
      "water     1.518379\n",
      "small     1.510663\n",
      "Name: 7, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 8:\n",
      "----------\n",
      "percent     5.692225\n",
      "rate        3.095470\n",
      "rise        3.018077\n",
      "price       2.950052\n",
      "market      2.740575\n",
      "increase    2.153777\n",
      "fall        2.073452\n",
      "low         2.058887\n",
      "report      1.933019\n",
      "average     1.675313\n",
      "Name: 8, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 9:\n",
      "----------\n",
      "political     3.467393\n",
      "campaign      3.388748\n",
      "vote          3.109589\n",
      "party         2.999487\n",
      "republican    2.901835\n",
      "election      2.897060\n",
      "candidate     2.842426\n",
      "democratic    2.539888\n",
      "voter         2.328566\n",
      "state         2.177667\n",
      "Name: 9, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 10:\n",
      "----------\n",
      "music          5.078406\n",
      "performance    2.581875\n",
      "play           2.432180\n",
      "perform        2.292476\n",
      "song           2.255920\n",
      "concert        2.099615\n",
      "dance          1.894327\n",
      "night          1.893033\n",
      "sound          1.813494\n",
      "program        1.753961\n",
      "Name: 10, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 11:\n",
      "----------\n",
      "president    7.350104\n",
      "executive    5.217573\n",
      "chief        3.351524\n",
      "director     3.202695\n",
      "vice         3.190214\n",
      "name         2.436043\n",
      "chairman     2.025625\n",
      "job          1.726798\n",
      "group        1.537582\n",
      "board        1.513726\n",
      "Name: 11, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 12:\n",
      "----------\n",
      "patient      2.660094\n",
      "drug         2.616199\n",
      "health       2.595414\n",
      "doctor       2.421976\n",
      "study        2.409690\n",
      "medical      1.960041\n",
      "group        1.855709\n",
      "cause        1.675597\n",
      "percent      1.653554\n",
      "treatment    1.607615\n",
      "Name: 12, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 13:\n",
      "----------\n",
      "official         6.244894\n",
      "report           3.707489\n",
      "investigation    1.621335\n",
      "agency           1.619772\n",
      "spokesman        1.488034\n",
      "office           1.470690\n",
      "public           1.447191\n",
      "tell             1.186232\n",
      "information      1.163531\n",
      "accord           1.074361\n",
      "Name: 13, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 14:\n",
      "----------\n",
      "case      4.509725\n",
      "court     3.699988\n",
      "lawyer    3.571145\n",
      "law       3.405216\n",
      "judge     2.444055\n",
      "state     2.244615\n",
      "charge    2.054600\n",
      "legal     1.940094\n",
      "trial     1.809887\n",
      "rule      1.552431\n",
      "Name: 14, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 15:\n",
      "----------\n",
      "computer       2.344945\n",
      "system         2.263548\n",
      "service        2.061009\n",
      "company        1.598535\n",
      "offer          1.519225\n",
      "technology     1.497542\n",
      "information    1.444705\n",
      "program        1.328116\n",
      "available      1.300264\n",
      "number         1.300152\n",
      "Name: 15, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 16:\n",
      "----------\n",
      "father       4.763414\n",
      "graduate     3.697768\n",
      "son          3.420770\n",
      "mrs          3.195651\n",
      "daughter     3.024597\n",
      "mother       2.851801\n",
      "marry        2.323276\n",
      "receive      2.247643\n",
      "yesterday    1.816839\n",
      "degree       1.736568\n",
      "Name: 16, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 17:\n",
      "----------\n",
      "school       6.678582\n",
      "student      5.100397\n",
      "child        3.065832\n",
      "education    2.372618\n",
      "teacher      2.112062\n",
      "parent       2.054553\n",
      "college      1.995312\n",
      "program      1.879941\n",
      "class        1.841157\n",
      "public       1.262745\n",
      "Name: 17, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 18:\n",
      "----------\n",
      "plan           2.412670\n",
      "meeting        2.085357\n",
      "agreement      1.818328\n",
      "leader         1.761757\n",
      "meet           1.581330\n",
      "agree          1.449898\n",
      "deal           1.311713\n",
      "member         1.234448\n",
      "negotiation    1.193364\n",
      "group          1.182627\n",
      "Name: 18, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 19:\n",
      "----------\n",
      "book      4.299755\n",
      "write     4.238103\n",
      "life      3.503378\n",
      "author    1.771739\n",
      "story     1.713960\n",
      "world     1.629413\n",
      "writer    1.554740\n",
      "read      1.534959\n",
      "novel     1.512606\n",
      "family    1.495644\n",
      "Name: 19, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 20:\n",
      "----------\n",
      "film          4.131841\n",
      "play          3.530939\n",
      "movie         3.225084\n",
      "television    2.505446\n",
      "character     2.189725\n",
      "director      2.058222\n",
      "production    2.003076\n",
      "star          1.758573\n",
      "actor         1.745932\n",
      "direct        1.629567\n",
      "Name: 20, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 21:\n",
      "----------\n",
      "man      7.254852\n",
      "woman    7.077818\n",
      "young    2.506171\n",
      "black    1.073584\n",
      "life     0.949054\n",
      "girl     0.910966\n",
      "wear     0.869130\n",
      "old      0.835862\n",
      "child    0.811672\n",
      "sex      0.764139\n",
      "Name: 21, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 22:\n",
      "----------\n",
      "art           3.412207\n",
      "artist        2.651026\n",
      "exhibition    2.244699\n",
      "museum        1.995013\n",
      "painting      1.962148\n",
      "collection    1.640635\n",
      "gallery       1.567017\n",
      "design        1.542740\n",
      "color         1.374370\n",
      "photograph    1.370709\n",
      "Name: 22, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 23:\n",
      "----------\n",
      "states           6.351720\n",
      "country          5.295184\n",
      "american         4.859559\n",
      "world            2.691143\n",
      "government       2.629451\n",
      "foreign          1.826640\n",
      "nation           1.655153\n",
      "international    1.623844\n",
      "economic         1.558923\n",
      "policy           1.330497\n",
      "Name: 23, dtype: float64\n",
      "----------\n",
      "\n",
      "Topico 24:\n",
      "----------\n",
      "force         4.089217\n",
      "military      3.635355\n",
      "war           3.055768\n",
      "troop         2.285546\n",
      "attack        2.174227\n",
      "soldier       1.781563\n",
      "kill          1.720779\n",
      "government    1.701606\n",
      "fight         1.409186\n",
      "american      1.320156\n",
      "Name: 24, dtype: float64\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precisamos criar uma lista de palavras que representam as \n",
    "# colunas da matriz de frequência de palavras\n",
    "words = vocabs\n",
    "\n",
    "# Vamos criar um dataframe para visualizar\n",
    "components_df = pd.DataFrame(nmf.components_, columns=words)\n",
    "\n",
    "# Vamos verificar as palavras que representam mais fortemente cada um dos tópicos\n",
    "for i in range(n_topics):\n",
    "    component = components_df.iloc[i]\n",
    "    print(\"Topico {}:\".format(i))\n",
    "    print(\"----------\")\n",
    "    print(component.nlargest(10))\n",
    "    print(\"----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que os tópicos gerados são coerentes! Poderíamos facilmente associar cada um dos tópicos a um tema específico de uma matéria de jornal. Perceba o quanto isso é poderoso!\n",
    "\n",
    "Podemos ainda verificar quais são os tópicos principais de alguns artigos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc 0</th>\n",
       "      <th>doc 1</th>\n",
       "      <th>doc 2</th>\n",
       "      <th>doc 3</th>\n",
       "      <th>doc 4</th>\n",
       "      <th>doc 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic 0</th>\n",
       "      <td>0.138997</td>\n",
       "      <td>0.112087</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.324801</td>\n",
       "      <td>0.020204</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193594</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188557</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020459</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 4</th>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.049269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074578</td>\n",
       "      <td>0.040884</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099410</td>\n",
       "      <td>0.036020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051634</td>\n",
       "      <td>0.034271</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 7</th>\n",
       "      <td>0.143605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 8</th>\n",
       "      <td>0.244761</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276004</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.466707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 11</th>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245987</td>\n",
       "      <td>0.063296</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 12</th>\n",
       "      <td>0.334051</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 13</th>\n",
       "      <td>0.048596</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 14</th>\n",
       "      <td>0.037677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641285</td>\n",
       "      <td>0.112541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094671</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>0.043601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.184761</td>\n",
       "      <td>0.036262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026016</td>\n",
       "      <td>0.069601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 19</th>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.106886</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113493</td>\n",
       "      <td>0.345957</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025977</td>\n",
       "      <td>0.116479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 23</th>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.231619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic 24</th>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             doc 0     doc 1     doc 2     doc 3     doc 4     doc 5\n",
       "topic 0   0.138997  0.112087  0.062792  0.324801  0.020204  0.000000\n",
       "topic 1   0.000000  0.193594  0.004431  0.000000  0.188557  0.000000\n",
       "topic 2   0.000000  0.017124  0.000000  0.098219  0.000000  0.030034\n",
       "topic 3   0.000000  0.006128  0.000000  0.020459  0.007947  0.000000\n",
       "topic 4   0.000962  0.049269  0.000000  0.074578  0.040884  0.000000\n",
       "topic 5   0.000000  0.099079  0.000000  0.000000  0.099410  0.036020\n",
       "topic 6   0.000000  0.056428  0.000000  0.051634  0.034271  0.010995\n",
       "topic 7   0.143605  0.000000  0.000000  0.013844  0.000000  0.000000\n",
       "topic 8   0.244761  0.007141  0.000000  0.276004  0.011112  0.000000\n",
       "topic 9   0.000000  0.036408  0.000000  0.019394  0.044359  0.000000\n",
       "topic 10  0.000000  0.000000  0.017977  0.466707  0.000000  0.000000\n",
       "topic 11  0.033735  0.000000  0.000000  0.245987  0.063296  0.000000\n",
       "topic 12  0.334051  0.001380  0.000000  0.000000  0.170245  0.000000\n",
       "topic 13  0.048596  0.054898  0.000000  0.163529  0.000000  0.000000\n",
       "topic 14  0.037677  0.000000  0.000000  0.000000  0.641285  0.112541\n",
       "topic 15  0.000000  0.000000  0.094671  0.088666  0.043601  0.000000\n",
       "topic 16  0.000000  0.004509  0.004817  0.001996  0.184761  0.036262\n",
       "topic 17  0.000000  0.000000  0.000000  0.026016  0.069601  0.000000\n",
       "topic 18  0.000000  0.000000  0.000000  0.018711  0.000000  0.000000\n",
       "topic 19  0.038768  0.033813  0.019272  0.002710  0.106886  0.000000\n",
       "topic 20  0.000000  0.020436  0.000000  0.053244  0.000000  0.000000\n",
       "topic 21  0.000000  0.000000  0.000000  0.113493  0.345957  0.000000\n",
       "topic 22  0.000000  0.000000  0.025977  0.116479  0.000000  0.000000\n",
       "topic 23  0.072706  0.231619  0.000000  0.150897  0.000000  0.031606\n",
       "topic 24  0.012247  0.006525  0.000000  0.000000  0.076012  0.000000"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precisamos criar um dataframe para facilitar nossa vida\n",
    "df = pd.DataFrame(data=W_nmf.T, \n",
    "                  columns=['doc {}'.format(i) for i in range(n_doc)], \n",
    "                  index=['topic {}'.format(i) for i in range(n_topics)])\n",
    "df.loc[:,'doc 0':'doc 5'].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que os documentos são compostos por diversos tópicos diferentes. Isso faz todo o sentido se pensarmos que as notícias não são tão específicas ao ponto de falar apenas de um único tema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de recomendação\n",
    "\n",
    "Em poucos anos a internet revolucionou o mercado de consumo mundial e a forma como os clientes interagem com os vendedores. Uma das dinâmicas criadas mais importantes a partir dessa revolução é a de sistemas de recomendação. Todos devem já ter notado o quanto e-commerces como a Amazon, Best Buy e até empresas brasileiras acertam ao recomendar certos tipos de produto para seus clientes, que muitas vezes nem os estavam procurando (veja esse [artigo](https://www.techemergence.com/use-cases-recommendation-systems/)). Isso não acontece mais apenas em e-commerces, mas também com provedores de música (Spotify), de filmes (Netflix) ou vídeos em geral (Youtube). \n",
    "\n",
    "Esse fenômeno só ocorre devido a um fator: **dado**. As empresas atualmente possuem muita informação sobre os seus produtos e os seus usuários. É muito fácil obter, hoje em dia, os interesses dos clientes sobre seus produtos. Seja o fato de o vendedor comprar um produto, dar um review ou apenas clicar, já é suficiente para uma empresa mapear os interesses dos usuários e tentar direcionar produtos que seriam relevantes para o usuário sem nem mesmo ele saber!\n",
    "\n",
    "Os sistemas de recomendação se baseiam, basicamente, em encontrar relações entre compradores e produtos. Mais especificamente, existem dois grandes grupos de sistemas de recomendação:\n",
    "- **Proximidade de produtos**: Tem o objetivo de encontrar produtos similares aos consumidos por um cliente. Se um cliente possui o interesse em um determinado produto, o sistema de recomendação pode tentar encontrar outros produtos similares para indicar para o cliente.\n",
    "- **Proximidade entre clientes** (Filtro Colaborativo): Tem o objetivo de encontrar clientes com interesses semelhantes. Suponha que exista um cliente X que consuma os produtos A e B, enquanto um outro cliente Y tem interesse nos produtos A, B e C. Como eles possuem interesses semelhantes (produtos A e B), o sistema de recomendação poderia indicar o produto C para o cliente X.\n",
    "\n",
    "Existem diversos outros tipos de sistemas de recomendação que fogem do escopo desse material. Mais informações podem ser vistas nesse [link](https://www.techemergence.com/use-cases-recommendation-systems/).\n",
    "\n",
    "##### Exemplo\n",
    "Agora vamos tentar criar um sistema simples de recomendação baseado em **proximidade de produtos**! \n",
    "\n",
    "Vamos utilizar o dataset de artigos do NY Times para essa tarefa. Vamos supor que uma pessoa tenha lido um determinado artigo e nós gostaríamos de recomendar outros artigos semelhantes àquele. Lembre que para comparar dois documentos que contém vetores de atributos associados a palavras, a melhor medida de distância é a **distância de cossenos**.\n",
    "\n",
    "Para calcular a distância entre produtos, nós poderíamos utilizar todo o espaço de atributos (quantidade de palavras no vocabulário), mas isso é desnecessário. Nós temos uma representação resumida de cada documento por sua proporção de tópicos, que formam o novo vetor de atributos. Como já encontramos os tópicos relacionados aos documentos no exercício anterior, podemos aproveitá-los para resolver nosso problema atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nós vamos ter que normalizar o vetor de atributos\n",
    "# Isso é necessário para que todas as features (tópicos) \n",
    "# de um documento some 1 ao final\n",
    "# Seria a porcentagem de composição dos tópicos \n",
    "# no documento\n",
    "from sklearn.preprocessing import normalize\n",
    "W_nmf_norm = normalize(W_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>topic 5</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "      <th>topic 9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic 15</th>\n",
       "      <th>topic 16</th>\n",
       "      <th>topic 17</th>\n",
       "      <th>topic 18</th>\n",
       "      <th>topic 19</th>\n",
       "      <th>topic 20</th>\n",
       "      <th>topic 21</th>\n",
       "      <th>topic 22</th>\n",
       "      <th>topic 23</th>\n",
       "      <th>topic 24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc 0</th>\n",
       "      <td>0.294146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303896</td>\n",
       "      <td>0.517961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153861</td>\n",
       "      <td>0.025917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 1</th>\n",
       "      <td>0.316441</td>\n",
       "      <td>0.546551</td>\n",
       "      <td>0.048343</td>\n",
       "      <td>0.017302</td>\n",
       "      <td>0.139095</td>\n",
       "      <td>0.279719</td>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.102785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095460</td>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653904</td>\n",
       "      <td>0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 2</th>\n",
       "      <td>0.524771</td>\n",
       "      <td>0.037032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791191</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 3</th>\n",
       "      <td>0.431515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130489</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>0.099081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068598</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.366686</td>\n",
       "      <td>0.025766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117798</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.034564</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.070738</td>\n",
       "      <td>0.150782</td>\n",
       "      <td>0.154748</td>\n",
       "      <td>0.200475</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc 4</th>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.229870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.049841</td>\n",
       "      <td>0.121191</td>\n",
       "      <td>0.041780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.054078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053154</td>\n",
       "      <td>0.225243</td>\n",
       "      <td>0.084851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic 0   topic 1   topic 2   topic 3   topic 4   topic 5   topic 6  \\\n",
       "doc 0  0.294146  0.000000  0.000000  0.000000  0.002036  0.000000  0.000000   \n",
       "doc 1  0.316441  0.546551  0.048343  0.017302  0.139095  0.279719  0.159308   \n",
       "doc 2  0.524771  0.037032  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "doc 3  0.431515  0.000000  0.130489  0.027181  0.099081  0.000000  0.068598   \n",
       "doc 4  0.024630  0.229870  0.000000  0.009689  0.049841  0.121191  0.041780   \n",
       "\n",
       "        topic 7   topic 8   topic 9    ...     topic 15  topic 16  topic 17  \\\n",
       "doc 0  0.303896  0.517961  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "doc 1  0.000000  0.020161  0.102785    ...     0.000000  0.012730  0.000000   \n",
       "doc 2  0.000000  0.000000  0.000000    ...     0.791191  0.040254  0.000000   \n",
       "doc 3  0.018393  0.366686  0.025766    ...     0.117798  0.002651  0.034564   \n",
       "doc 4  0.000000  0.013547  0.054078    ...     0.053154  0.225243  0.084851   \n",
       "\n",
       "       topic 18  topic 19  topic 20  topic 21  topic 22  topic 23  topic 24  \n",
       "doc 0  0.000000  0.082041  0.000000  0.000000  0.000000  0.153861  0.025917  \n",
       "doc 1  0.000000  0.095460  0.057694  0.000000  0.000000  0.653904  0.018420  \n",
       "doc 2  0.000000  0.161058  0.000000  0.000000  0.217096  0.000000  0.000000  \n",
       "doc 3  0.024858  0.003601  0.070738  0.150782  0.154748  0.200475  0.000000  \n",
       "doc 4  0.000000  0.130305  0.000000  0.421757  0.000000  0.000000  0.092667  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos criar um dataframe:\n",
    "# índice: documento\n",
    "# colunas: vetor de features (normalizadas)\n",
    "df = pd.DataFrame(W_nmf_norm,\n",
    "                  columns=['topic {}'.format(i) for i in range(n_topics)],\n",
    "                  index=['doc {}'.format(i) for i in range(n_doc)])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7618"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos escolher um documento aleatoriamente\n",
    "# Esse documento será o escolhido pelo cliente\n",
    "doc_target = np.random.choice(range(len(documents)))\n",
    "doc_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0     0.133103\n",
      "topic 1     0.575644\n",
      "topic 2     0.051933\n",
      "topic 3     0.000000\n",
      "topic 4     0.550594\n",
      "topic 5     0.025231\n",
      "topic 6     0.424973\n",
      "topic 7     0.139334\n",
      "topic 8     0.206514\n",
      "topic 9     0.107456\n",
      "topic 10    0.000000\n",
      "topic 11    0.000000\n",
      "topic 12    0.161399\n",
      "topic 13    0.000000\n",
      "topic 14    0.000000\n",
      "topic 15    0.000000\n",
      "topic 16    0.140682\n",
      "topic 17    0.000000\n",
      "topic 18    0.000000\n",
      "topic 19    0.000000\n",
      "topic 20    0.000000\n",
      "topic 21    0.135645\n",
      "topic 22    0.154468\n",
      "topic 23    0.000000\n",
      "topic 24    0.046040\n",
      "Name: doc 7618, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verifica o vetor de features dele:\n",
    "doc_target_features = df.iloc[doc_target]\n",
    "print(doc_target_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontre agora os documentos mais próximos a esse documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artigos recomendados:\n",
      "doc 1313    0.911258\n",
      "doc 3083    0.905729\n",
      "doc 4974    0.901671\n",
      "doc 3370    0.883303\n",
      "doc 5165    0.870204\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcula a distância de cossenos entre o artigo e \n",
    "# todos os outros documentos\n",
    "cossine_distance = df.dot(doc_target_features)\n",
    "\n",
    "# Todos os documentos com maior distância de cossenos \n",
    "# representam os documentos mais próximos\n",
    "print(\"Artigos recomendados:\")\n",
    "recommendations = cossine_distance.nlargest(6)[1:]\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos visualizar os principais tópicos desses documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artigo original: doc 7618\n",
      "-----------------------\n",
      "- Tópicos (palavras): \n",
      "        topic 1 (thing, tell, ask, feel, lot)\n",
      "        topic 4 (city, building, area, build, house)\n",
      "        topic 6 (pay, money, state, budget, tax)\n",
      "\n",
      "\n",
      "\n",
      "Recomendação doc 1313:\n",
      "-----------------------\n",
      "- Similaridade: 91.13%\n",
      "- Tópicos (palavras): \n",
      "        topic 1 (thing, tell, ask, feel, lot)\n",
      "        topic 6 (pay, money, state, budget, tax)\n",
      "        topic 4 (city, building, area, build, house)\n",
      "\n",
      "\n",
      "Recomendação doc 3083:\n",
      "-----------------------\n",
      "- Similaridade: 90.57%\n",
      "- Tópicos (palavras): \n",
      "        topic 1 (thing, tell, ask, feel, lot)\n",
      "        topic 4 (city, building, area, build, house)\n",
      "        topic 6 (pay, money, state, budget, tax)\n",
      "\n",
      "\n",
      "Recomendação doc 4974:\n",
      "-----------------------\n",
      "- Similaridade: 90.17%\n",
      "- Tópicos (palavras): \n",
      "        topic 1 (thing, tell, ask, feel, lot)\n",
      "       topic 22 (art, artist, exhibition, museum, painting)\n",
      "        topic 6 (pay, money, state, budget, tax)\n",
      "\n",
      "\n",
      "Recomendação doc 3370:\n",
      "-----------------------\n",
      "- Similaridade: 88.33%\n",
      "- Tópicos (palavras): \n",
      "        topic 4 (city, building, area, build, house)\n",
      "        topic 1 (thing, tell, ask, feel, lot)\n",
      "        topic 6 (pay, money, state, budget, tax)\n",
      "\n",
      "\n",
      "Recomendação doc 5165:\n",
      "-----------------------\n",
      "- Similaridade: 87.02%\n",
      "- Tópicos (palavras): \n",
      "        topic 4 (city, building, area, build, house)\n",
      "        topic 1 (thing, tell, ask, feel, lot)\n",
      "        topic 6 (pay, money, state, budget, tax)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_top_topics = df.iloc[doc_target].nlargest(3).index.values\n",
    "default_components = [components_df.iloc[int(i.split(' ')[1])].nlargest(5).index.values \n",
    "                      for i in default_top_topics]\n",
    "\n",
    "print(\"Artigo original: doc {}\".format(doc_target))\n",
    "print(\"-----------------------\")\n",
    "print(\"- Tópicos (palavras): \")\n",
    "for i in range(len(top_topics)):\n",
    "    print(\"{:>15} ({})\".format(default_top_topics[i], ', '.join(default_components[i])))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for doc, similarity in recommendations.items():\n",
    "    doc_num = int(doc.split(' ')[1])\n",
    "    top_topics = df.iloc[doc_num].nlargest(3).index.values\n",
    "    components = [components_df.iloc[int(i.split(' ')[1])].nlargest(5).index.values for i in top_topics]\n",
    "    print(\"Recomendação {}:\".format(doc))\n",
    "    print(\"-----------------------\")\n",
    "    print(\"- Similaridade: {:.2%}\".format(similarity))\n",
    "    print(\"- Tópicos (palavras): \")\n",
    "    for i in range(len(top_topics)):\n",
    "        print(\"{:>15} ({})\".format(top_topics[i], ', '.join(components[i])))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que os tópicos são realmente semelhantes. Poderíamos recomendar esses produtos para o cliente!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
